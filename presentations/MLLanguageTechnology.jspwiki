!!!Language technology for low-resource languages

Jack Rueter and Sjur Moshagen

!!!Rule-based language technology

Our rule-based approach:
* two-level morphology (finite state transducers)
* disambiguation using constraint grammar

Both technologies developed here at HU :-)

!!Word-level technology

* Morphophonology:
** twolc (a "variant" of SPE phonology)
** also rewrite rules ("real" SPE phonology)
* Morphology: lexc

Both formalisms should be easily recognisable by linguists.

!Example — twolc

{{{
Alphabet m p ;

Rules

"N:m rule"
N:m <=>  _ p: ;

"p:m rule"
p:m <=> :m _  ;
}}}

Target changes:

{{{
kaNpat
kammat
}}}

!Example — rewrite rules

The same changes written using rewrite rules:

{{{
[ N -> m || _ p ]
.o.
[ p -> m || m _ ];
}}}

Rewrite rules are ordered, twolc rules are not.

!Example — lexc

A very simplistic English lexicon:

{{{
Multichar_Symbols
+V +Pres +3Sg +PresPtc +Past

! Lexicon containing lexical stems:
LEXICON Root
 walk V ;
 talk V ;
 pack V ;

! Lexicon containing POS tag only:
LEXICON V
 +V: V-suff ;

! Lexicon containing inflectional suffixes and corresponding tags:
LEXICON V-suff
 +Pres+3Sg:s   # ;
     +Past:ed  # ;
  +PresPtc:ing # ;
     +Pres:    # ;
}}}

!Summary

End result: computer model of morphology and morphophonology. This model can
analyse and generate word forms.

!!Sentence level technology

VISLCG3, an extended version of the original Constraint Grammar syntax developed
by Karlsson et al. VISLCG3 is maintained and developed in Odense, Denmark. It is
open source.

Constraint grammars work "backwards": instead of imposing a structure on a
sentence, it selects or removes invalid readings given a certain contexts. By eliminating readings over and over again, one should be left with only the correct readings. From the [CG-3 tutorial|http://visl.sdu.dk/cg3_howto.pdf]:

{{{
(a) REMOVE VFIN IF (-1 ART) ;
(b) REMOVE (N) IF (-1 (PERS NOM)) ;
}}}

(a) will remove finite verb readings (the target) from a cohort, if the one
immediately to the left (-1) contains an article tag, while (b) will remove noun
readings in the presence of an immediately preceding personal pronoun in the
nominative, thus disambiguating nominal-verbal ambiguities like hit in ”the
hit/they hit”.

Note that the target VFIN is a defined set (e.g. consisting of tense or mode
tags), while the target (N) is a simple tag, declared as a set on-the-fly by
using parentheses.

Constraint grammars require a lot of manual work, but will generally achieve
substantially higher scores than similar tools using other techniques (given
enough work).

!!!Tools for linguistic research

* explicit grammars
* analysers
* generators
* analysed text
* try out different phonological models of a language
* use model to process (analyse) text

!!Explicit Grammars

* Writing for a computer forces you to be explicit about every aspect of the
  grammar.
* This can bring forth new areas of the grammar to research. Examples from the
  work on the Sámi languages:
** compounding
** derivations
** phonological alternations in Inari Sami
** North Sámi syntax

!!Analysers

* morphological analysers can themselves be used as a tool for resarch (see
  "Analysing text", next)
* a full-size lexicon can be used as source material for lexical research

!!Generators

* morphological generators will ruthlessly display all overgenerations, and thus
  give valuable feedback about the grammar model, and the assumptions built in.

!!Use Model To Process (Analyse) Text

* The most important use of a morphological analyser is to analyse text.
  Together with disambiguation and syntactic analysis, this can be used to
  build an analysed corpus that can be searched for different linguistic
  patterns.

=> [Korp|http://gtweb.uit.no/korp/]
   (searchable corpus of analysed texts)

[images/Korp.png]

!!!Tools for speakers of minority languages

* keyboards (desktop and mobile, soon with spellers)
* spell checkers
* morphologically aware hyphenators
* morphologically aware dictionaries
* grammar checkers
* MT
* iCALL
* text-to-speech

!!Keyboards
* Desktop (Windows, macOS, Linux/X11)
* Mobile, soon with spellers

Without keyboards, writing texts in any language can become almost impossible.
The first step of building language technology for a language is thus to make a
keyboard.

Using the keyboard part of the Giella infrastructure,
the amount of work needed to produce installable keyboards is minimal. But
effort should be put into the desing of the keyboard such that it will work
optimally for the language community. Actually building the installation
packages is a matter of minutes.

* [Skolt Sami desktop keyboard|../keyboards/kbdlangdocs/sms/doc/layout.html]
* [Inari Sami mobile keyboard|images/android_writing.no.png]

!Layout definition

The layout definition is done using yaml syntax, and is just the following:

{{{
modes:
  mobile-default: |
    á š e r t y u i o p â
    a s d f g h j k l ä đ
      ž z č c v b n m ŋ
  mobile-shift: |
    Á Š E R T Y U I O P Â
    A S D F G H J K L Ä Đ
      Ž Z Č C V B N M Ŋ
}}}

!!Spell Checkers

* The next tool to develop is typically a spell checker.
* This is especially important for minority languages, because the minority
  position often causes language users to be less or very little exposed to
  their own language, and they are thus often unsure of the correct spelling.
* The speller is essentially the lexical fst pluss an error model to create
  suggestions for misspelled words
* presently all spellers built using the Giella infrastructure is using Hfst

!!Morphologically Aware Hyphenators
!!Morphologically Aware Dictionaries
!!Grammar Checkers
!!Mt
!!Icall
!!Text-To-Speech




