<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN"
"http://forrest.apache.org/dtd/document-v20.dtd">
<document xml:lang="en">
  <header>
    <title>Development tools</title>
  </header>

  <body>
    <section>
      <title>Development tools</title>

      <p>The project manipulates text in many ways, organized in lexicons.</p>

      <section>
        <title>Editors</title>

        <p>To edit our source file we need a text editor, which has to support
        UTF-8, and can save the edited result as pure text. The tools also have 
        to be <a href="utf-8-setup.html">setup</a> to handle the utf-8 
        encoding. You may use <a href="docu-emacs.html">emacs</a> and it's
        <a href="docu-emacs-modes.html">modes</a> On a Mac you may use
        <a href="subethaedit.html">SubEthaEdit</a>.</p>
      </section>

      <section>
        <title>Documentation tools</title>

        <p>We publish our documentation with <a href="../infra/forrest-howto.html">forrest</a>. 
        To edit these documents you need at least a text
        editor, and we recommend <a href="xml-mind.html">XMLMind</a>.</p>
      </section>

      <section>
        <title>Morphological analysis</title>

        <p>The project uses the following Xerox tools: <strong>twolc</strong>
        (for morphophonology), <strong>lexc</strong> (for morphology),
        <strong>xfst</strong> (for compiling the final transducer) , and
        <strong>lookup</strong> (for analysis and generation).</p>

        <p>The link list below refers to the Xerox documentation pages for
        these tools, these and other links are found <a
        href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/">here</a>:</p>

        <ol>
          <li><a
          href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/docs/twolc-92/twolc92.html">twolc</a>,
          for phonological and morphophonological rules</li>

          <li><a
          href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/docs/lexc-93/lexc93.html">lexc</a>,
          for representing the Sami stems and the affix lexica</li>

          <li><a
          href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/docs/fst-97/xfst97.html">xfst</a>,
          the finite-state transducer tool, for integratingthe different parts
          of the program, and for compiling the preprocessor</li>

          <li><a
          href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/docs/tokenize-97/tokenize97.html">tokenize</a>,
          for tokenization and processing (note that we do not use tokenize
          for preprocessing at the moment, but perl)</li>

          <li><a
          href="http://www.xrce.xerox.com/competencies/content-analysis/fssoft/docs/lookup-97/lookup97.html">lookup</a>,
          an interface to the morphological analyser. NB! cf. our <a
          href="docu-lookup.html">lookup notes</a></li>
        </ol>

        <p>The programs are activated by printing e.g. <code>lexc</code> and
        then pressing the enter key. The tools are documented in Karttunen /
        Beesley <a href="http://www.fsmbook.com">Finite-State Morphology:
        Xerox Tools and Techniques</a>. The tools may also be
        installed on your own machine, be it on Mac OSX, Linux or Windows. One
        version of the software is found on the CD accompanying the book, for
        the latest version, ask Trond for reference.</p>
      </section>

      <section>
        <title>Disambiguation tools</title>

        <ol>
          <li><a href="../ling/docu-disambiguation.html">Morphological
          disambiguation</a></li>

          <li><a href="docu-lookup2cg.html">lookup2cg</a>, a script to
          transform Xerox output to CG input</li>
        </ol>
      </section>

      <section>
        <title>Analysis and testing</title>

        <p>The easiest and the most effective way to do this (although a
        little scary at first) is to use commandline tools. We have made a
        <a href="docu-unix.html">short introduction</a> in English and a
        longer <a href="docu-unix-nno.html">document</a> in Norwegian on
        this topic. The <a href="docu-sme-manual.html">introduction</a>
        on how to use our parser is also an excellent introduction on how to
        combine the individual tools.</p>
      </section>

      <section>
        <title>Our home-made tools, and adjustments of public tools</title>

        <ol>
          <li><a href="../infra/docu-cgi-bin.html">The cgi-bin setup for making the
          parsers accessible on the web</a></li>

          <li><a href="paradigm_presentation.html">How the generated paradigms should be presented at web</a></li>

          <li><a href="../infra/docu-webinterface.html">The web interface to our web
          demo</a></li>

          <li><a href="docu-conversionscripts.html">Conversion
          scripts</a></li>

          <li><a href="../ling/docu-testing.html">Testing tools</a></li>

          <li><a href="docu-tools-emacs.html">Emacs for lexicon
          expansion</a></li>

          <li><a href="docu-emacs-modes.html">Special emacs
          modes</a></li>
          <li><a href="autshumato.html">Autshumato CAT platform</a></li>
        </ol>
      </section>
      <section>
        <title>Other tools</title>

        <ol>
                  <li><a href="../tools/tca2.html">tca2</a>, the corpus alignment program.</li>
                  <li><a href="salignment.html">Evaluating other sentence alignment programs</a>.</li>
        </ol>
      </section>

    </section>
  </body>
</document>