!!!Corpus maintenance

This document discusses measures to improve the corpus conversion process.

Note also the [sentence alignment page|../tools/tca2.html], which looks
into that specific sub-part of the corpus maintenance.


!!Spring 2011 corpus improvement project meetings

* [Corpus meeting 7.4.2011|../admin/corpus/Meeting_2011-04-07.html]
* [Corpus meeting 11.4.2011|../admin/corpus/Meeting_2011-04-11.html]
* [Corpus meeting 3.5.2011|../admin/corpus/Meeting_2011-05-03.html]


!!!Corpus errors

!!Algorithm for dealing with OCR errors

!Finding these errors

* Problem: There are document-specific conversion errors that result
  in letters, not in garbage, errors that can be found only by linguistic
  means.
* Solution: identify the problematic files via error detection with fst

__TODO__:

Tne Error Detection Algorithm runs as follows:

# For each file:
## Analyse the main language text morphologically
## Count the missing ones
## Register the missing/total ratio, and pick the worst files
# Look at the worst files, and figure out how to mend them, or move them,
 e.g. to an OCR gold standard 
 
 
!Results of finding errors for North Sami

Here is a list of errors per file in each folder in the admin directory. For each file we list ''error/total ratio - total number of words - words not recognized - filename'', and we sort the file list according to error/total ratio:
* [admin/depts/others|corpus_errors_admin_depts_others.txt]
* [admin/guovda|corpus_errors_admin_guovda.txt]
* [admin/others|corpus_errors_admin_others.txt]
* [admin/regjering|corpus_errors_admin_regjering.txt]
* [admin/sd/others|corpus_errors_admin_sd_others.txt]
* [admin/sd/samediggi|corpus_errors_admin_sd_samediggi.txt]
* [sma corpus errors|corpus_errors_sma.txt]
* [sma corpus error analysis|corpus_errors_sma_analysis.txt]
* [sme corpus errors analysis|corpus_errors_analysis.txt]
* [sme corpus errors admin/|corpus_errors_sme_admin.txt]
* [sme corpus errors analysis|corpus_errors_sme_analysis.txt]
* [sme corpus errors guovda/|corpus_errors_sme_guovda.txt]
* [sme corpus errors regjering/|corpus_errors_sme_regjering.txt]
* [smj corpus errors|corpus_errors_smj.txt]
* [smj corpus error analysis|corpus_errors_smj_analysis.txt]

 

A list of error analyses can be found from [corpus error analysis|corpus_errors_analysis.txt].

Error typology (summarising the corpus error analysis):

* Conversion errors
** ==> Improve conversion
* Typing errors
** ==> Add to typos.txt, evt. move to typos gold corpus
* Linguistic spelling errors
** ==> Add to typos.txt, evt. move to typos gold corpus
* Scanning errors
** ==> Analyse the scanning errors and add search-replace to xsl file
* Language recognition errors
** ==> Check whether the xsl file lists the relevant languages
** ==> Improve language rec module
* Numbers not recognised
** ==> Improve fst
* Unknown words (bad fst)
** ==> Improve fst
* Corrupted original
** ==> Consider removing it

__TODO:__
* Improve conversion according to error type, as sketched above
 

!Results of finding errors for South Sami

* [April 20 Analysis of sma corpus|corpus_errors_sma.txt], and [breakdown of the error types|corpus_errors_sma_analysis.txt].


__TODO:__
* Sma improvement of the test results above
 
!Finding catalogue errors:

List all files in langX-catalogue with more non-langX content than
langX-content.

__TODO:__ 
* Still not done.

!Correcting OCR errors

Develop algorithms for automatic correction of OCR errors. This 
work must be done separately for each language.


!!Errors addressed so far:

* dårlege originalfiler - gjev ugyldig xml
** desse blir fanga opp i dag
* kodefeil - desse gjev gyldig xml, men meiningslause bokstavar
** utf-som-macroman
** utf-som-latin1
** utf-som-html-hex
** utf-som-html-entitet
* skannefeil/ocr-feil - desse gjev meiningsfulle bokstavar, men meiningslaus tekst
** đ-som ó, osv.
* bad sentence-delimitation: one real sentence is one fragment in one language,
  3 fragments in the other -> alignment goes bunk
* files {{freecorpus/converted/sme/admin/others/}} 
** {{STM200420050011000SE_PDFS.pdf.xml}} 
  {{STM200420050044000SE_PDFS.pdf.xml}}
  have encoding errors that đ is represented as &nbsp; and the document is full of
  &nbsp;'s; thus these files should be deleted
** file {{OTP200620070025000SE_PDFS.pdf.xml}}
  has paragraphs with content '--------' so it should be deleted.
** file {{STM200320040010000SE_PDFA.pdf.xml}}
  has so many errors, it should be rescanned
** {{uito-ohpenplana.txt.xml}}
  the original file is corrupted


!!!Cleaning up the catalogues

Many documents are parallel with the parallel content in the same file.
Other documents are simply placed in the wrong catalogues. Algorithm
to fix this:

# For each file, count the number of words
# For each file, count the number of words marked with the language of
  the catalogue
# Estimate the ratio
# Pick the files with a bad ratio, and investigate them. Split and reallocate.


!!!Corpus conversion targets

As a reminder, this is what we aim at:

# Sentence-aligned bilingual corpus for CAT 
# Analysed mono- and bilingual corpus
## Lemmatised and word-aligned for terminology
## Fully analysed and presented for linguistic work and terminology
