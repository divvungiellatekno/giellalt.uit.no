<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN"
"http://forrest.apache.org/dtd/document-v20.dtd">
<document xml:lang="en">
  <header>
    <title>Using the preprocessor for the Giellatekno/Divvun languages</title>
  </header>

  <body>
      <p>The preprocessor splits text into tokens (sentences and words).</p>

    <section>
      <title>Using Hfst as a preprocessor</title>

      <p>The  command is as follows:</p>
      <source>cat testfile.txt | hfst-tokenise --giella-cg tools/tokenisers/tokeniser-disamb-gt-desc.pmhfst| vislcg3 -g tools/tokenisers/mwe-dis.cg3 | cg-mwesplit | vislcg3 -g src/syntax/disambiguator.cg3</source>

      <p>Please note that in order to use this command, you must
      explicitly configure the system to build the file
      <code>tools/tokenisers/tokeniser-disamb-gt-desc.pmhfst</code>.
      The configuration command is:</p>
      <source>./configure --with-hfst --enable-tokenisers</source>
      
      <p>Here the different parts of the preprocess command (above) is explained:</p>
      <source>
	cat testfile.txt | \
	hfst-tokenize --giella-cg --weight-classes=1 tools/tokenisers/tokeniser-disamb-gt-desc.pmhfst | \
	# tokenize and analyse, with constraint grammar as setting
	vislcg3 -g tools/tokenisers/mwe-dis.cg3 | cg-mwesplit | \
	# identify, disambiguate and format  multiword expressions
	vislcg3 -g src/syntax/disambiguator.cg3
	# and then to normal disambiguation, and eventually further steps
      </source>

      <p>With this command, text is tokenised, analysed and the output
      is printed in VISLCG3 format, all in one go, and everything
      using a single transducer. This will handle multiword
      expressions properly, including all inflections of them. This
      setup replaces the older, Perl-based solution for the Xerox
      tools.
      </p>

    </section>

    <section>
      <title>Our old preprocess method: Using the perl script preprocess</title>

            <p>Below follows the description for how to use the Perl-based solution
      we have been using so far.</p>

      <source>Usage: preprocess [OPTIONS] FILE
Split text in FILE into sentences and words.
Options (note that for most languages not all options are available):

-connect=&lt;list&gt;  comma separated list of words which connect expressions
                 like fisk- og vilthandelen
--corr=&lt;file&gt;    Use the list of common typos and their corrections (e.g. typos.txt)
--abbr=&lt;file&gt;    Use the list of abbreviations
--break=&lt;string&gt; Add &lt;string&gt; instead of . as a sentence delimiter after abbreviations.
--hyph           Show the hyphenation points, i.e. change the &lt;hyph&gt; tags
-h               to hyphens. The default is to just remove the &lt;hyph&gt; tags.
--use-hyph-tags  Leave the &lt;hyph&gt; tags untouched
--space          Preserve space.
-s
--ltag=&lt;string&gt;  Left tag for space, default &lt;
--rtag=&lt;string&gt;  Right tag for space, default &gt;
--help           Print the help text and exit.
--v              Print information of the execution of the script
--xml            Accept xml-formatted input, print each tag on its own line.
-x
--no-xml-out     Used together with --xml, does not print the xml-tags.
-n</source>

      <p>Example use:</p>

      <source>cat file.txt | preprocess --abbr=$GTHOME/langs/sma/tools/tokenisers/abbr.txt | lookup ...</source>
      </section>


      <p class="last_modified">Last modified: $Date$, by
      $Author$</p>

  </body>
</document>
