
Dictionary for administrative language

* Meeting 16.2.2011.
* Present: Børre, Cip, Fran, Trond.


!!!Status quo

* Conversion to xml
** Conversion works. The parallel texts are converted. Closed. 
** Conversion continues with incoming files, but outside this project. 
* Parallel texts
** all is doable apart from the regjeringen.no files that have "?" in the path:
** this is not fixed in the xslt scripts
*** Status (including samediggi protocols) nob2sme: 1022 file pairs. sme2nob: 1020 file pairs
*** Missing in this number: the ? filename parallel files
*** Børre is changing the ? in the names, changing ? to _.
*** Time frame: The name conversion is done before noon tomorrow.
** The anchor.txt
*** cut -d"/" -f2,4 anchor.txt
*** We might need less words and more words in the anchor list
*** Look at the 50-250 wordforms in the corpus, check whether they miss in the 
    anchor list, and eventually add. But anchor list improvement is
    on the todo list for after this process. (it will require testing on
    a gold corpus etc).
* Sentence alignment
** Not started
** Problem1: ? in file names. Solution underway: Use _.
** Problem2: (encountered by @cip): sentences like 
   __<s id="asdfasd">/ /  //</s>__
   are not accepted by the tca2 sentence aligner and these should
   be filtered right after indexing. Solution: this is not
   a problem.  
** C and B to discuss the tca2 problems after this meeting., 
   C sends B his aligner.
** More steps to be discussed by B and C (file indexing etc.)   
* Word alignment
** Input: tmx files. Fran needs the whole bunch.
* Lexicographic work
** Not started, this is for the lexicographer, after the word alignment.


!!!Plan forward, dates

# Conversion
## Done
# Parallelisation
## Fix file names (__B, C__) ?
## Done by the end of 18.2. (as discussed by B/C)
# Sentence alignment -- tca2
## Done by 22.2 next week
# Word alignment
## Previous steps must be done before startup.
## Starting 22.2, deadline 1.3.
# Lexicography




!!!Notes


FMT: The word alignment actually takes quite a bit of manual work, in order to process with the analysers, remove the unnecessary formatting and stripping the appropriate tags. It is ideal if this is only done once. In actual amount of time spent it isn't a huge amount -- a day or so. But we won't get useful result
 until we get __most__ of the text anyway (at the moment I hvae something like 3-4 files) -- also it doesn't make sense for the lexicographer to look at half-finished output. 
 


