# FAD- og korpusmøte 13.11.2012


Til stades: Ciprian, Trond, Sjur, Børre


#  Saker:


* Status
* Oslo-Bergen-tagger
* Wikipedia
* Ukjente ord
* Parallellkorpus og prosessering
* Autshumato
* Neste møte




# Status


Ciprian har byrja testa kvart enkelt steg i parallellføringsprosesseringa:
* kva som går inn
* kva som kjem ut
* kva vi hadde venta oss vs kva vi får


Oppsummering: mykje er bra, nokre punkt som Ciprian skal sjekka enno. Notatar i `statistics_fad.xml`.


# Oslo-Bergen-tagger


Uløyseleg problem med split compounds, må fiksast i preprossessering før OBT-analyse.


## Problem


```
hum-tf4-ans143:obt ttr000$ echo "Jorden var øde og tom, og mørke lå over havdypet. " | ./bin/mtag-osx64 |vislcg3  -g src/nob_morf.cg3


"<jorden>"
	"jord" subst appell mask be ent
"<var>"
	"være" verb pret a5 pr1 pr2 <aux1/perf_part>
"<øde>"
	"øde" adj ub m/f ent pos
	"øde" adj fl pos
	"øde" subst appell nøyt ub ent
	"øde" adj nøyt ub ent pos
"<og>"
	"og" konj
"<tom>"
	"tom" adj ub m/f ent pos
"<,>"
	"$," <komma>
"<og>"
	"og" konj clb
"<mørke>"
	"mørk" adj fl pos
	"mørke" subst appell nøyt ub ent
"<lå>"
	"ligge" verb pret i2 tr11 pa4 a5
"<over>"
	"over" prep
"<havdypet>"
	"havdyp" subst appell nøyt be ent
"<.>"
	"$." clb <punkt>






hum-tf4-ans143:obt ttr000$ echo "Jorden var øde og tom, og mørke lå over havdypet. " | ./bin/mtag-osx64 |vislcg3  -g src/nob_morf-prestat.cg3  | OBT-Stat/bin/run_obt_stat.rb


"<jorden>"
	"jord" subst appell mask be ent
"<var>"
	"være" verb pret a5 pr1 pr2 <aux1/perf_part>
"<øde>"
	"øde" adj ub m/f ent pos
"<og>"
	"og" konj
"<tom>"
	"tom" adj ub m/f ent pos
"<,>"
	"$," <komma>
"<og>"
	"og" konj clb
"<mørke>"
	"mørke" subst appell nøyt ub ent
"<lå>"
	"ligge" verb pret i2 tr11 pa4 a5
"<over>"
	"over" prep
"<havdypet>"
	"havdyp" subst appell nøyt be ent
"<.>"
	"$." clb <punkt>
```


## Oppsummering


```
sme unknown:
cat data.tagged.clean.sme | PERL_UNICODE=D perl -p -e 's/ /\n/g' | grep unknown | wc -l
   tokens 39014 (20121014)
          39212 (20121028)
          38481 (20121102)
          38650 (20121112)
cat data.tagged.clean.sme | PERL_UNICODE=D perl -p -e 's/ /\n/g' | grep unknown | sort | uniq -c | sort -nr | wc -l
  types 19725 (20121014)
        20701 (20121028)
        20535 (20121102)
        21103 (20121112)


nob ukjent:
cat data.tagged.clean.nob | PERL_UNICODE=D perl -p -e 's/ /\n/g' | grep '<ukjent>' | wc -l
  tokens 17140 (20121014)
         11060 (20121028)
         10952 (20121102)
         11007 (20121112)


cat data.tagged.clean.nob | PERL_UNICODE=D perl -p -e 's/ /\n/g' | grep '<ukjent>' | sort | uniq -c | sort -nr | wc -l
   types 4083 (20121014)
         3426 (20121028)
         3431 (20121102)
         3453 (20121112)
```


# Wikipedia


Tronds vs. Ciprians verkty.


* Tronds verkty er WikiExtractor.py, dokumentert
  [her](/ling/WikipediaAsCorpus.html).
* Ciprian sitt verkty er `WP2TXT`, dokumentert i README-fila, finst
  [her](http://wp2txt.rubyforge.org).


Ciprian vil ha kvalitetssikra verktya for å trekkja ut tekst frå WP: Trond sitt verkty vs Ciprian sitt.


Det største problemet: Ugyldige UTF-8-teikn. Må sjekkast.


**GJERAST:**
* sjekk ugyldige UTF-8-sekvensar (**Trond**)


# Ukjente ord


Alle bindestrekar er no fjerna, som reduserte ukjende ord i NOB med ca 1/3. Det meste av resten er støy. Det same gjeld SME - dei fleste ukjende ord no er støy.


Dette punktet er avslutta for denne gong.


# Parallellkorpus og prosessering


Alle testar og sjekkar for metadatakonsistens bør utvidast til å bli brukt på heile korpuset, og for alle språk. Alle ikkje-samiske språk **må** ha minst ein samisk parallell (dvs språk utan kopling til samisk er ikkje interessant i utgangspunktet, og unnatak må merkast tydeleg). Det finst andre nykkelspråk - t.d. komi, eller andre minoritetsspråk. Men reine majoritetsspråkstekstar vil vi ikkje ha.


**GJERAST:**
* generalisera og utvida testane til heile korpus og alle språk
  (**Børre, Ciprian**)


# Autshumato


##  Status quo


Trond har kompletert dokumentasjonen, og sjekka kor mykje av dokumentasjonen vi
kan visa til andre. /tools/autshumato.html


Resultat etter testing:
* omsetjingsminnet funkar bra, både med OpenOffice, og med Word-filer
** problem: tekst-filer får feil med UTF-8
** løysing: ein må starta Java med rett encoding-parameter
* har ikkje testa MT (feil språkpar / retning)
* "Glossary" **funkar**. Glossary = terminologi som rein tekst (TSV) eller tbx-fil.
* "Dictionary" funkar ikkje? Dictionary = StarDict-format,
  Autshumato leverer kanskje berre funksjonailitet på Windows.
  Dette må testast og arbeidast vidare med.
* Hunspell: funkar på Linux i Omega-T, truleg er det eit
  DLL-problem (dvs som over, Autshumato kjem berre med
  Windows-DLL, og med Linux- og Mac-bibliotek burde Hunspell funka der òg.


Enkel terminologi/"glossary" kan lagast slik:


```
vold:veahkaválddálašvuohta # ;


cat ~/main/words/dicts/nobsme/bin/nobsme.lexc \|
cut -d" " -f1|tr '_' ' '|tr ':' '\t'|grep -v LEXIC \|
> ~/Documents/tm/nobsme_glossary.txt
```


## Oppsummering


Vi er ganske nære, men det er framleis mykje arbeid med å testa, laga manglande
ressursar og dokumentera, ev. laga ferdige installeringspakker.
Vi har mykje anna på gang no, så vi ventar til etter Akilles (=FAD).


#  Neste møte


Tysdag 20. november kl 10.30 finsk tid.












