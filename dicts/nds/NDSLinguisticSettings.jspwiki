!!! Neahttadigis√°nit linguistic settings

The documentation here concerns the directory, and subdirectories in
''language_specific_rules/'', and is divided into the following sections:

1. Paradigms 
2. Contexts
3. Tagsets
4. User-friendly tags

If you update these files, be sure to run the test procedure and restart the
service, as explained in [Updating|NDSUpdatingDictionaries.html], but don't
forget to check in any new files created.

!! Paradigm generation

Paradigms are managed by a file and directory structure.

! Paradigm folder structure

{{{
    paradigms/sme/common_nouns.paradigm
    paradigms/sme/proper_nouns.paradigm
    paradigms/sme/paradigm_group/foo.paradigm
    paradigms/sme/paradigm_group/bar.paradigm
}}}

Paradigms can be ordered however in each directory, and may be grouped
for convenience into other folders. A language typically won't need
many, and usually there will be one base paradigm for a part of
speech from which additional paradigms apply to subsets of words in
this part of speech.

Currently, there is no explicit setting for ordering the rules, and ordering is
determined by the complexity of the rules that match a given word and entry.
Thus, if one rule looks for ''pos'', ''valence'' and ''context'', and another
only looks for ''pos'' and ''valence'', the former will be applied if both
match.

Symlinks in this directory are also tolerated, so if multiple language variants
need to use the same rule set, simply make a symlink between the directories.

For some more advanced examples, see the rules for ''sme'' (particularly, tanta
pluralia rules).

! Paradigm file format

Paradigm files are structured in the following way: one part is YAML, and the
other part is data in [Jinja|jinja.pocoo.org/docs/templates/] format.
Essentially what this says is, if the first part's (YAML) conditions are
matched, then we render the following template for the paradigm, and pass
it off to the generator tool.

{{{
    name: "Proper noun paradigm"
    description: |
      Generate the proper noun if the entry contains sem_type="Prop" or
      "prop"
    morphology:
      pos: "N"
    lexicon:
      XPATH:
        sem_type: ".//l/@type"
      sem_type: 
        - "Prop"
        - "prop"
    --
    {{ lemma }}+N+Prop+Sem/Plc+Sg+Gen
    {{ lemma }}+N+Prop+Sem/Plc+Sg+Ill
    {{ lemma }}+N+Prop+Sem/Plc+Sg+Loc
}}}

YAML settings:

 * {{name}} - A short name to display when the service is loading (required)
 * {{description}} (optional) - More words for other developers
 * {{morphology}}, {{lexicon}} - one of these must be present, but both may be
   present as well

! Conditions together

Operating together, what the conditions essentially say is that for any
user-inputted wordform, if the analyzer rules find a matching analysis, 
and the lexicon rules find a matching lexicon entry, then the paradigm
will be used for the entries where these align.

! Morphology conditions

Conditions that are possible to match on are set up in a variety of
ways. Analyzer conditions may be specified in the ''analyzer'' key,
and each key under that may be a tagset and a value, or a whole tag:

{{{
    morphology:
      pos: "V"
      infinitive: true

    ... is the same as ...

    morphology:
      tag: "V+Inf"

    ... or ... 

    morphology:
      tag: 
        - "V+Inf1"
        - "V+Inf2"
}}}

Either a value may be specified, or boolean 'true', which stands for
'any member of the tag set is present'. A list may also be specified, 
which is in effect a kind of locally defined tagset.

One other key that might be used for the analyzer is 'lemma', which is
also present for lexicon, assuming that you only want the rule to apply
to a specific lemma.

    morphology:
      lemma: "diehtit"

NB: if there are problems matching a tag set, make sure that it is defined in
the language's corresponding tagset.

! Lexicon conditions

The lexicon is also usable for providing conditions for a particular
paradigm. Some predefined keys are available, and it is also possible
to use XPATH statements to test against individual XML entries.

{{{
    lexicon:
      XPATH:
        sem_type: ".//l/@sem_type"
      sem_type: "Plc"
      
    lexicon:
      XPATH:
        sem_type: ".//l/@sem_type"
      sem_type: 
        - "Plc"
        - "Something"
}}}

! Paradigm definition

Paradigm definition is mostly plaintext, but since it is a template, it
is possible to do all sorts of template operations.

    {{ lemma }}+N+Sg+Nom
    {{ lemma }}+N+Sg+Acc

Certain variables are available by default:

  - ''lemma''

Additional variables are available as they are defined by the conditions, and
the variable will be set to the matched condition:

{{{
    lexicon:
      XPATH:
        some_attribute: ".//l/@some_ttribute"
      some_attribute:
        - "Foo"
        - "Bar"
    --
    {{ lemma }}+Adj+{{ some_attribute }}
}}}

It is also possible to specify additional variables that are not used in the
match condition:

{{{
    lexicon:
      XPATH:
        some_attribute: ".//l/@some_ttribute"
        another: ".//l/@another_attribute"
      some_attribute:
        - "Foo"
        - "Bar"
    --
    {% if another %}
    {{ lemma }}+Adj+{{ some_attribute }}+{{ another }}
    {% else %}
    {{ lemma }}+Adj+{{ some_attribute }}
    {% endif %}
}}}

! Things to think about

This is more of a TODO for developers...

* Pregenerated paradigms could be accomplished by a template, but it would
  be fairly complex, and thus would require good access to ''lxml'' nodes
  without lots of complex template tags and custom filters. 


!! Contexts


For now this isn't entirely in line with the way Paradigm Generation
works, but it should be good enough for linguists to see the pattern and
work accordingly.

''.context'' files in each directory control what is displayed with the
generated wordform. The filename may be anything, so long as the suffix
is ''.context''. For convenience, ''sme'' and ''sma'' match filenames between
paradigms and context, but there is no need to do so, and one ''.context''
file could be used for everything.

! File structure

Context files are simply a YAML list, and each item is a dictionary
with the following keys:
 
* {{ entry_context }} - matches the ''@context'' attribute on each ''<l />''
   node. Set to a string, or None
* {{ tag_context }} - matches the tag used in generation. String. Must be
   set to something, as none would overgenerate.
* {{ template }} - jinja-format string, which accepts certain variables:

Template variables allowed:

* {{ word_form }} - inserts the wordform
* {{ context }} - inserts the context (usually not necessary)

Some examples:

{{{
    - entry_context: "sii"
      tag_context: "V+Ind+Prs+Pl3"
      template: "(odne sii) {{ word_form }}"
}}}

The above would thus generate:

{{{
    (odne sii) deaivvadit
}}}

Example without entry_context:

{{{
    - entry_context: None
      tag_context: "V+Ind+Prs+Sg1"
      template: "(daan biejjien manne) {{ word_form }}"
}}}

Note the lack of quotes around "None".

Otherwise, see the checked in files for more examples.

!! Tagsets

Tagsets are necessary for constructing certain types of rules for manipulating
lexical information and morphological information, either for generating forms,
or analyzing input, or even determining how entries should be displayed...
However, tagsets crucially operate on morphological analyzer output. Tagsets
are particularly integral in defining paradigms.

The ''pos'' tagset is also particularly important, because it helps match up
morphological analyses with lexicon entries, as the lexicon lookup will include
''pos'' when a value is available. If entries in the search results appear to
be out of line, and do not match by ''pos'', one of the causes may be that a
''pos'' is missing from the list.

Tagsets are file based because this makes it easier to duplicate them for
language variants, or share languages across dictionary instances--
particularly majority languages, for which it is easy to forget to check
settings for when they are used in multiple installations.

Symlinks in this directory are also permitted, if two language variants (i.e.
''SoMe'' and ''sme'') need to share a tagset.

! Tagset files

Each language has its own set of tagsets, and these are defined in a file in:

{{{
    configs/language_specific_rules/tagsets/
}}}

The filename must be ''ISO.tagset'', where ISO is a variable for the 3-character
language ISO (even for languages like ''se'', which should be listed in this
directory as ''sme'').

The file format is YAML, and all that is permitted here is key-value settings,
where the key is the name of the tagset, and the value is a list of tags that
fit into this tagset.

! Example

Here's an example of some tagsets from ''sme'':

{{{
    pos:
     - "N"
     - "V"
     - "A"
     - "Pr"
     - "Po"
     - "Num"
     - "CS"
     - "CC"
     - "pron."
     - "subst."
     - "verb"
     - "adj."
     - "konj."
    type: 
     - "NomAg"
     - "G3"
     - "aktor"
     - "res."
     - "Prop"
     - "prop."
    number: ["Sg", "Pl"]
}}}

Note that YAML allows you to define lists in multiple ways, and strings may be
quoted or non-quoted, however, it is often a good idea to quote them anyway,
because certain values like ''no'' and ''yes'' may be translated to boolean values
''True'' and ''False'', instead of being used as plain strings.

The above example also shows the two alternate list formats, one with brackets,
and the other with hyphens.

Note that comments are also allowed (marked with ''#''), and it may be useful
to document some sets as needed.

## More YAML documentation

http://en.wikipedia.org/wiki/YAML#Lists

!! User-friendly tags

{{{
    configs/language_specific_rules/user_friendly_tags/*.relabel
}}}

Each file is named with a suffix ''.relabel'', but the name may be
anything. Organize tag relabel sets however you will, maybe on a
language-pair to language-pair basis, or by dictionary set instead.

Consider that you may have to repeat some tagsets, so maybe using YAML
aliases will make things easier.

## File structure

The file structure is quite simple, and at most it must contain a list
called ''Relabel''. Each list item is a dictionary containing the keys:

 * ''source_morphology'' - The morphology name, usually an ISO, but
   sometimes something else in the case of language variants. (''sme'',
   ''SoMe'', ''kpv'')
 * ''target_ui_language'' - The language the user is browsing in-- must
   be an ISO.
 * ''tags'' - A dictionary of tags.

### Example

{{{
    Relabel:

      - source_morphology: 'kpv'
        target_ui_language: 'eng'
        tags: &some_alias_name
          V: "v."
          N: "n."
          A: "adj."

      - source_morphology: 'kpv'
        target_ui_language: 'fin'
        tags: &another_alias
          V: "v."
          N: "s."
          A: "adj."
          DO_NOT_SHOW: ""

      - source_morphology: "zzz"
        target_ui_language: "www"
        tags:
          <<: *some_alias_name
          <<: *another_alias

}}}

The last item in the list shows an example of inheriting from two
sources. Thus, the resulting tags will be:

{{{
          V: "v."
          N: "s."
          A: "adj."
          DO_NOT_SHOW: ""
}}}

You can even set tags in another location, outside of the ''Relabel''
list, if necessary.

{{{
    Aliases:
      tag_set_one: &some_alias_name
        V: "v."
        N: "n."
        A: "adj."

    Relabel:
      - source_morphology: 'kpv'
        target_ui_language: 'eng'
        tags: 
          <<: *some_alias_name

  }}}


